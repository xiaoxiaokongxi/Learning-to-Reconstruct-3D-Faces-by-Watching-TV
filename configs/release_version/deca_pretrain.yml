
# Why:
# training with only lmk loss for good initialization, 
# because the use of photometric loss needs good initialization both in regression and optimization
# and also, photometric loss needs differentiable rendering that makes the training slow
# 
# 
output_dir: "/content/drive/MyDrive/Colab_Notebooks/NewDECA/Pre"
# pretrained_modelpath: "/content/drive/MyDrive/Colab_Notebooks/NewDECA/Detail/"
pretrained_modelpath: " "
dataset:
  batch_size: 16
  K: 1
loss:
  photo: 0.
  id: 0.
  useSeg: False
  reg_tex: 0.
  reg_light: 0.
  shape_consistency: False
train:
  resume: True
  max_epochs: 200
  max_steps: 100000
  log_steps: 10
  vis_steps: 500
  checkpoint_steps: 1000
  val_steps: 500
  eval_steps: 1000
